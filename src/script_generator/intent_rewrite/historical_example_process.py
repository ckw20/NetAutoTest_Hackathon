import sys
import os
import json
from openai import OpenAI
# å°†é¡¹ç›®æ ¹è·¯å¾„åŠ å…¥åˆ° sys.path ä¸­
sys.path.insert(0, "/root/NetAutoTest")
from src.utils.extract_api import *
from src.script_generator.common import *
import yaml
from concurrent.futures import ProcessPoolExecutor, as_completed
import time
from tqdm import tqdm

def load_prompt_template(yaml_path: str):
    with open(yaml_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    return config


def split_intent_code(lines: str):

    # æå–ä»¥ # å¼€å¤´çš„æ³¨é‡Šè¡Œä¸º intentï¼Œç›´åˆ°é‡åˆ°éæ³¨é‡Šè¡Œä¸ºæ­¢
    intent_lines = []
    code_started = False
    code_lines = []

    for line in lines:
        stripped = line.strip()
        if not code_started and stripped.startswith("#"):
            intent_lines.append(line.replace("#",""))
        else:
            code_started = True
            code_lines.append(line)

    intent = "".join(intent_lines).strip()
    code = "".join(code_lines).strip()

    return intent,code

def translate_intent(url: str, key: str, intent: str,model: str):
    client = OpenAI(
        api_key=key, 
        base_url=url,
    )
    messages = [
        {"role": "system", "content": "You are a translator. Please translate the following Chinese text into English accurately, keeping technical terms.Output only the English intention, without any extra content."},
        {"role": "user", "content": intent}
    ]
    response = client.chat.completions.create(
        model=model,
        messages=messages
    )
    return response.choices[0].message.content.strip()


def llm(model, intent, code, api_list, prompt_template,key,url ):
    client = OpenAI(
        api_key=key, 
        base_url=url,
    )

    # # åŠ è½½å¹¶å¡«å…… prompt
    # prompt_template = load_config(prompt_path)

    prompt = prompt_template.format(intent=intent, code=code, api_list=";\n".join(api_list))
    print(">> prompt:\n",prompt)
    messages = [{"role": "system", "content": prompt}]

    response = client.chat.completions.create(
        model=model,
        messages=messages
    )

    content = response.choices[0].message.content
    print("==== LLM Output ====")
    print(content)
    return content,prompt



def match_api_descriptions(content, api_json_path):

    # è¯»å– JSON æ–‡ä»¶ä¸­çš„æ‰€æœ‰ API å®šä¹‰
    with open(api_json_path, 'r', encoding='utf-8') as f:
        api_data = json.load(f)

    api_functions=list(get_testerlib_base_functions("".join(content), 'TesterLibrary.base'))

    matched_apis = []

    for entry in api_data:
        full_name = entry.get("method_name", "")
        func_name = full_name.split('.')[-1]  # å–å‡½æ•°åæœ€åä¸€çº§

        if func_name in api_functions:
            matched_apis.append(
                func_name+":"+entry.get("description", ""),
            )

    return matched_apis






def llm_with_retry(model, intent, code, functions, prompt_template, api_key,base_url,retries=10, wait_sec=10):
    for attempt in range(1, retries + 1):
        try:
            return llm(model, intent, code, functions, prompt_template,api_key,base_url)
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {attempt} æ¬¡è°ƒç”¨ llm å¤±è´¥ï¼š{e}")
            if attempt < retries:
                print(f"â³ æ­£åœ¨ç­‰å¾… {wait_sec} ç§’åé‡è¯•...")
                time.sleep(wait_sec)
            else:
                print("âŒ å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡è¯¥ç”¨ä¾‹ã€‚")
                return None, None





def load_examples(root_dir):
   
    py_file_list = []
    for dirpath, _, filenames in os.walk(root_dir):
        for f in filenames:
            if f.endswith('.py'):
                py_file_list.append(os.path.join(dirpath, f))

    return py_file_list


def load_cepri_dev_new(root_dir):
    py_file_list = []
    subdirs = [entry for entry in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, entry))]
    for entry in subdirs:
        case_dir = os.path.join(root_dir, entry)
        main_path = os.path.join(case_dir, 'main.py')
        if os.path.exists(main_path):
            py_file_list.append(main_path)
        else:
            print(f"è·³è¿‡ï¼š{main_path} ä¸å­˜åœ¨")
            continue
            
    return py_file_list



def process_one_case(args):
    """ å•ä¸ªç”¨ä¾‹å¤„ç†é€»è¾‘ï¼ˆå¯è¢«å¹¶è¡Œè°ƒç”¨ï¼‰ """
    py_path, api_json_path, prompt_template, model ,api_key,base_url= args
    try:
        with open(py_path, 'r', encoding='utf-8') as f:
            content = f.readlines()

        functions = match_api_descriptions(content, api_json_path)
        intent, code = split_intent_code(content)

        intent_en = translate_intent(base_url, api_key,intent,model)

        rewrite_intent, prompt = llm_with_retry(model, intent_en, code, functions, prompt_template,api_key,base_url)

        if rewrite_intent is None:
            return None

        return {
            "path": py_path,
            "intent": intent,
            "intent_en": intent_en,
            "code": code,
            "functions": functions,
            "rewrite_intent": rewrite_intent,
            "prompt": prompt
        }

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥ï¼š{py_path}ï¼Œé”™è¯¯ï¼š{e}")
        return None


def load_config(yaml_path: str) -> dict:
    with open(yaml_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

if __name__ == "__main__":
    start_time=time.time()
    json_path="/root/NetAutoTest/data/rewrite_results/all_python_results_english.json"
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    listed=[item["path"] for item in data]

    config_path = "/root/NetAutoTest/src/script_generator/intent_rewrite/prompts/example_process_config.yaml"
    config = load_config(config_path)


    prompt_path = '/root/NetAutoTest/src/script_generator/intent_rewrite/prompts/prompt_example_process_english_v2.yaml'
    prompt_template=load_config(prompt_path)["prompt_template"]

    # åŠ è½½ç”¨ä¾‹è·¯å¾„åˆ—è¡¨
    examples_py_file_list = load_examples(config["examples_root_dir"])
    cepri_dev_new_py_file_list = load_cepri_dev_new(config["cepri_dev_new_root_dir"])
    py_file_list = examples_py_file_list + cepri_dev_new_py_file_list
    py_file_list_=[]
    for i in py_file_list:
        if i not in listed:
            py_file_list_.append(i)

    print(">> examples_py_file_list ä¸ªæ•° :", len(examples_py_file_list))
    print(">> cepri_dev_new_py_file_list ä¸ªæ•° :", len(cepri_dev_new_py_file_list))
    print(">> ç”¨ä¾‹æ€»ä¸ªæ•° :", len(py_file_list))
    print(">> ç”¨ä¾‹æ€»ä¸ªæ•° :", len(py_file_list_))

    # âœ… æ„é€ å¹¶è¡Œå‚æ•°
    task_args = [(path, config["api_json_path"], prompt_template, config["model"],config["api_key"],config["base_url"]) for path in py_file_list_]

    results = []
    with ProcessPoolExecutor(max_workers=8) as executor:  # è®¾ç½®å¹¶å‘è¿›ç¨‹æ•°
        futures = [executor.submit(process_one_case, arg) for arg in task_args]

        for future in tqdm(as_completed(futures), total=len(futures), desc="ğŸš€ å¹¶è¡Œå¤„ç†ä¸­"):
            result = future.result()
            if result:
                results.append(result)

    # ä¿å­˜æœ€ç»ˆç»“æœ
    output_json_path=config["output_json_path"]          
    os.makedirs(os.path.dirname(output_json_path), exist_ok=True)
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    end_time=time.time()
    elapsed=end_time-start_time
    print(f"\nâœ… å¹¶è¡Œå¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶ï¼š{elapsed:.2f} ç§’ï¼Œå…±æˆåŠŸå¤„ç† {len(results)} ä¸ªç”¨ä¾‹ï¼Œç»“æœä¿å­˜åˆ°ï¼š{output_json_path}")
    



# if __name__ == "__main__":
#     path = '/root/NetAutoTest/data/ref_projects/cepri-dev-new/Testcase/tc_6_7_6/main.py'
#     prompt_path = '/root/NetAutoTest/src/script_generator/intent_rewrite/prompts/intent_rewrite.yaml'  #  prompt.yaml çš„è·¯å¾„
    
#     model = "deepseek-r1"

#     content = open(path, 'r', encoding='utf-8').readlines()

#     api_json_path="/root/NetAutoTest/data/parsed_documents/API_docs/last_llm_result_with_names.json"
#     functions = match_api_descriptions(content,api_json_path)

#     intent, code = split_intent_code(content)

#     print(">> Extracted Intent:\n", intent)
#     print(">> Extracted Code:\n", code)
#     print(">> Extracted API List:\n", functions)

#     rewrite_intent,prompt=llm(model, intent, code, functions, prompt_path)

